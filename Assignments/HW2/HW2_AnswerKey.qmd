---
title: "GR5224 Homework 2, Due July 28, 2025 at 6PM"
format: 
  pdf:
    number-sections: true
    documentclass: article
    include-in-header:
      text: |
        \usepackage{amsmath}
        \usepackage{fullpage}
pdf-engine: xelatex
editor: visual
execute: 
  echo: true
keep-tex: true
---

A dataset was collected by Charles Gaba on deaths from covid at the county level, which can be found [here](https://docs.google.com/spreadsheets/d/100BFc0VppVL8CIhaNh5ZiTFGBNCnGBdYzfqISAWxln8/). You could download the "Vaccination Rates" worksheet to your home directory in various formats, but I executed the following in R

```{r}
#| output: false

library(dplyr)
library(stringr)

ROOT   <- "https://docs.google.com/spreadsheets/"
FILE   <- "d/100BFc0VppVL8CIhaNh5ZiTFGBNCnGBdYzfqISAWxln8/"
EXPORT <- "export?format=csv&id=100BFc0VppVL8CIhaNh5ZiTFGBNCnGBdYzfqISAWxln8&gid=0"

Gaba <- readr::read_csv(paste0(ROOT, FILE, EXPORT), progress = FALSE,
                        col_names = c("FIPS", "ST", "State", "County",
                                      "Trump_num", "Total_votes", "Trump_percent",
                                      "Pop", "two_doses_num", "two_doses_percent",
                                      "covid_deaths_2021", "covid_deaths_2022",
                                      "covid_deaths_diff", "death_rate"),
                        col_types = "iccccccccccccd", skip = 1) |>
  filter(!is.na(death_rate)) |>
  mutate(across(ends_with("_num"), ~ as.integer(str_remove_all(.x, ","))),
         across(contains("deaths_"), ~ as.integer(str_remove_all(.x, ","))),
         Total_votes = as.integer(str_remove_all(Total_votes, ",")),
         Pop = as.integer(str_remove_all(Pop, ",")),
         across(ends_with("_percent"), ~ as.numeric(str_remove_all(.x, "%"))))
```

```{r}
Gaba <- mutate(Gaba, 
               two_doses_percent = two_doses_percent / 10,
               Trump_percent = Trump_percent / 10)
```

# Binomial Model

## Prior on the Intercept

Assuming a death rate of $1$ in $750$ for an "average" county — which, in the United States, is quite rural — implies

```{r}
(m_0 <- qlogis(1 / 750))
s_0 <- 1 / 3
```

and a standard deviation of about one-third would be generous. For something like this, it only matters that the prior on $\gamma$ be roughly plausible because it will become very precisely estimated in the posterior distribution.

## Prior on the Vaccination Coefficient

If an individual has been fully vaccinated, it is almost impossible for them to die of covid in 2022. In addition, if the vaccination rate were 62 percent rather than 52 percent (in the average county) fewer unvaccinated people would get covid and thus would not die of covid. Thus, I might choose something like

```{r}
m_1 <- -0.2
s_1 <-  0.1
```

## Prior on the Voting Coefficient

It is less clear how increasing support for Trump while holding the vaccination rate constant would affect covid deaths, but it might be the case that it would result in less social distancing, masking, etc. Thus, the effect should be smaller than the vaccination effect but equally uncertain.

```{r}
m_2 <- 0.1
s_2 <- 0.1
```

## Prior Predictive Distribution

```{r}
R <- 10000
Manhattan <- filter(Gaba, FIPS == 36061)
deaths <- tibble(gamma  = rnorm(R, mean = m_0, sd = s_0),
                 beta_1 = rnorm(R, mean = m_1, sd = s_1),
                 beta_2 = rnorm(R, mean = m_2, sd = s_2),
                 alpha  = gamma - beta_1 * mean(Gaba$two_doses_percent) -
                   beta_2 * mean(Gaba$Trump_percent),
                 eta = alpha + beta_1 * Manhattan$two_doses_percent +
                   beta_2 * Manhattan$Trump_percent,
                 y = rbinom(R, size = Manhattan$Pop, prob = plogis(eta)))
```

```{r}
#| message: false
library(ggplot2)
ggplot(deaths) + 
  geom_density(aes(x = y)) +
  scale_x_log10() + 
  labs(x = "2022 deaths from covid in Manhattan")
```

When the horizontal axis is in log-units, the predicted covid death rate looks somewhat normal with a median that is a bit less than 1000. If this were plotted in the raw units, it would be highly right-skewed but would still have a median of a bit less than 1000.

## Posterior Distribution

```{r}
#| message: false
library(rstanarm)
options(mc.cores = parallel::detectCores())
```

```{r}
#| label: post_binom
#| cache: true
#| output: false
post_binom <- stan_glm(cbind(covid_deaths_2022, Pop - covid_deaths_2022) ~
                         two_doses_percent + Trump_percent,
                       family = binomial(link = "logit"),
                       data = Gaba,
                       prior_intercept = normal(m_0, s_0),
                       prior = normal(c(m_1, m_2), c(s_1, s_2)))
```

```{r}
print(post_binom, digits = 2)
```

```{r}
as_tibble(post_binom) |> 
  summarize(Pr_vax_neg   = mean(two_doses_percent < 0),
            Pr_Trump_pos = mean(Trump_percent > 0))
```

In both cases, we are essentially certain about the signs of the coefficients, or at least that the probability of a surprising sign is less than $1$ in $4000$ (which is the default number of MCMC draws).

## Posterior Predictive Distribution

```{r}
Manhattan_cf <- posterior_predict(post_binom,
                                  newdata = mutate(Manhattan, 
                                                   two_doses_percent = 10))
ggplot() + 
  geom_density(aes(x = Manhattan_cf)) + 
  geom_vline(aes(xintercept = Manhattan$covid_deaths_2022), color = "red")
```

The actual number of covid deaths in Manhattan during 2022 was $5501$ but about a third of those could have been prevented — under our model — had everyone been fully vaccinated.

# Negative Binomial Model

## Prior on the Overdispersion

$\phi$ should be rather small, which implies a lot more dispersion in deaths than would be predicted by a Poisson data-generating process. With something like a virus, some counties can more-or-less randomly be hit harder than others due to the presence or absence of super-spreading events. But I am relatively uncertain about $\phi$, so I will go with a half-Cauchy.

## Prior on the Intercept and Coefficients

Using an antilog inverse link function makes the expectation more sensitive to changes, so the coefficient values should be somewhat smaller and more certain.

```{r}
m_0 <- -log(750)
s_0 <- 0.25

m_1 <- 0.1
s_1 <- 0.05

m_2 <- 0.025
s_2 <- 0.025
```

## Prior Predictive Distribution in Hawaii

```{r}
HI <- filter(Gaba, State == "Hawaii")
deaths <- tibble(gamma  = rnorm(R, mean = m_0, sd = s_0),
                 beta_1 = rnorm(R, mean = m_1, sd = s_1),
                 beta_2 = rnorm(R, mean = m_2, sd = s_2),
                 alpha  = gamma - beta_1 * mean(Gaba$two_doses_percent) -
                   beta_2 * mean(Gaba$Trump_percent),
                 phi = abs(rcauchy(R))) |> 
  cross_join(HI) |> 
  mutate(eta = alpha + beta_1 * two_doses_percent + beta_2 * Trump_percent +
           log(Pop),
         mu = exp(eta),
         epsilon = rgamma(n(), shape = phi, rate = phi),
         y = rpois(n(), mu * epsilon))
```

```{r}
ggplot(deaths) +
  geom_density(aes(x = y)) + 
  scale_x_log10() +
  facet_wrap(~County)
```

These results mostly look reasonable with the horizontal axis is in log units. The predictive density for Kalawao seems to suffer from some artifacts due to it only having a population of 82. Obviously, it would not make sense to ever predict more than 82 people dying of covid in Kalawao, which is not enforced by our model. But it is correctly predicting there is a large chance of no or few covid deaths in Kalawao, so I am not too worried about the weird shape.

## Posterior Distribution

```{r}
#| label: post_NB
#| cache: true
#| output: false
post_NB <- stan_glm.nb(covid_deaths_2022 ~ offset(log(Pop)) + 
                         two_doses_percent + Trump_percent,
                       data = Gaba,
                       prior_intercept = normal(m_0, s_0),
                       prior = normal(c(m_1, m_2), c(s_1, s_2)),
                       prior_aux = cauchy(0, 1),
                       init_r = 1)
```

```{r}
print(post_NB, digits = 2)
```

```{r}
#| message: false
posterior_vs_prior(post_NB)
```

As anticipated under the prior, $\phi$ is not too big, although its posterior distribution is somewhat into the right tail of its prior distribution. Moreover, we became essentially certain as to its value. The substantive implication of overdispersion is that the *expected* number of covid deaths is much higher than the *modal* number of covid deaths.

This dynamic was at play during 2021 and 2022 especially where people acted like the pandemic was "over" because the most likely outcomes were not so bad, but prudent public health entails preparing for the distribution of outcomes (whose expectation was awful). This dynamic is still in play today where some people argue that the United States overreacted to covid in 2021 and 2022 because *ex post*, the outcomes were not so bad. However, the *ex ante* policy choices — in some realms — might have been an underreaction to the expected outcomes. But there are some decisions, such as the closing of in-person classes in schools, that are genuinely debatable because it depends on how what discount rate you apply to the long-term costs of lack of education in your utility function, as compared (mostly) to short-term death spikes.

## Model Choice

```{r}
mu_binom <- sweep(posterior_epred(post_binom), MARGIN = 2, STATS = Gaba$Pop, FUN = `*`)
mu_NB <- posterior_epred(post_NB)

error_binom <- sweep(mu_binom, MARGIN = 2, STATS = Gaba$covid_deaths_2022, FUN = `-`)
error_NB <- sweep(mu_NB, MARGIN = 2, STATS = Gaba$covid_deaths_2022, FUN = `-`)

summary(sqrt(rowMeans(error_binom^2)))
summary(sqrt(rowMeans(error_NB^2)))
```

The two models are essentially equivalent on the posterior distribution of the Root Mean Squared Error criterion (which may not be the best criterion). The average RMSE is a tiny bit lower for the binomial model, but I would argue that the binomial model is more appropriate because the total population in the county is a finite upper bound for the number of deaths.
